import json
from urllib.request import urlopen
import requests,json,os,sys,time,re
import pandas as pd
import numpy as np

r_part4=requests.get('http://steamspy.com/api.php?request=top100forever')
#r=requests.get('http://steamspy.com/api.php?request=all')
r_part4.content
dic_part4 = r_part4.json()
#dic_part4("median_forever")

total_count = 0
with open('app_part4.csv','w') as part_four:
    for game_id, game_details in dic_part4.items():
        total_count = total_count+1
        part_four.write(json.dumps({game_id:game_details}))
        part_four.write('\n')
        
dic_game_time = {'appid':{},'name':{},'median_forever':{}}
current_count = 0
for game_id,game_details in dic_part4.items():
    if game_details!={} and game_details is not None:
        dic_game_time['appid'].update({game_id:game_details.get("appid",{})})
        dic_game_time['name'].update({game_id:game_details.get('name',{})})
        dic_game_time['median_forever'].update({game_id:game_details.get('median_forever',{})})
    show_work_status(1,total_count,current_count)
    current_count+=1
    
 
df_user_links = pd.DataFrame(columns=['Links'])
 
#df_user_links['Links'].loc[0] = 'http://api.steampowered.com/IPlayerService/GetOwnedGames/v0001/?key=12342C69B72B036F8E660D95F28DF431&steamid=76561197960434622'+'&format=json'
#df_user_links['Links'].loc[1] = 'http://api.steampowered.com/IPlayerService/GetOwnedGames/v0001/?key=12342C69B72B036F8E660D95F28DF431&steamid=76561197960434622'+'&format=json'

new_row = {'Links':'http://api.steampowered.com/IPlayerService/GetOwnedGames/v0001/?key=12342C69B72B036F8E660D95F28DF431&steamid=76561197960434622'+'&format=json'}
df_user_links = df_user_links.append(new_row, ignore_index=True)

new_row = {'Links':'http://api.steampowered.com/IPlayerService/GetOwnedGames/v0001/?key=12342C69B72B036F8E660D95F28DF431&steamid=76561198016215597'+'&format=json'}
df_user_links = df_user_links.append(new_row, ignore_index=True)

new_row = {'Links':'http://api.steampowered.com/IPlayerService/GetOwnedGames/v0001/?key=12342C69B72B036F8E660D95F28DF431&steamid=76561198202525417'+'&format=json'}
df_user_links = df_user_links.append(new_row, ignore_index=True)

new_row = {'Links':'http://api.steampowered.com/IPlayerService/GetOwnedGames/v0001/?key=12342C69B72B036F8E660D95F28DF431&steamid=76561198089202086'+'&format=json'}
df_user_links = df_user_links.append(new_row, ignore_index=True)

new_row = {'Links':'http://api.steampowered.com/IPlayerService/GetOwnedGames/v0001/?key=12342C69B72B036F8E660D95F28DF431&steamid=76561198029242928'+'&format=json'}
df_user_links = df_user_links.append(new_row, ignore_index=True)

new_row = {'Links':'http://api.steampowered.com/IPlayerService/GetOwnedGames/v0001/?key=12342C69B72B036F8E660D95F28DF431&steamid=76561198014403181'+'&format=json'}
df_user_links = df_user_links.append(new_row, ignore_index=True)

new_row = {'Links':'http://api.steampowered.com/IPlayerService/GetOwnedGames/v0001/?key=12342C69B72B036F8E660D95F28DF431&steamid=76561198207433511'+'&format=json'}
df_user_links = df_user_links.append(new_row, ignore_index=True)

new_row = {'Links':'http://api.steampowered.com/IPlayerService/GetOwnedGames/v0001/?key=12342C69B72B036F8E660D95F28DF431&steamid=76561197966611389'+'&format=json'}
df_user_links = df_user_links.append(new_row, ignore_index=True)

new_row = {'Links':'http://api.steampowered.com/IPlayerService/GetOwnedGames/v0001/?key=12342C69B72B036F8E660D95F28DF431&steamid=76561198077345441'+'&format=json'}
df_user_links = df_user_links.append(new_row, ignore_index=True)

new_row = {'Links':'http://api.steampowered.com/IPlayerService/GetOwnedGames/v0001/?key=12342C69B72B036F8E660D95F28DF431&steamid=76561198089768783'+'&format=json'}
df_user_links = df_user_links.append(new_row, ignore_index=True)

new_row = {'Links':'http://api.steampowered.com/IPlayerService/GetOwnedGames/v0001/?key=12342C69B72B036F8E660D95F28DF431&steamid=76561198024696613'+'&format=json'}
df_user_links = df_user_links.append(new_row, ignore_index=True)

game_play_median = pd.DataFrame(dic_game_time)
game_play_median = game_play_median.rename(columns={'median_forever': 'Midian_playtime(min)'})
#game_play_median
#df = get_df(requests.get(df_user_links['Links'][0]))
#df.head(5)

##########################     Get the playtime data      ############################
def get_df(aa):
    ss = aa.json()
    sd = pd.DataFrame(ss['response']['games'])
    #sd.drop(sd.columns[[1,3, 4, 5]], axis = 1, inplace = True)

    no_zero = sd.loc[sd['playtime_forever']!=0]
#ddf_col = pd.concat([aaaa,game_play_median], axis=1)
    df_col = pd.merge(no_zero, game_play_median, on="appid")
    return df_col
    
######################## Assume the ratings  ###############
def get_ratings(df_col):
    df_col['Assuming_Ratings'] = 0
    for i in range(len(df_col)):
        if df_col['playtime_forever'][i]>= df_col['Midian_playtime(min)'][i]:
            df_col['Assuming_Ratings'][i] = 5
   
        elif df_col['Midian_playtime(min)'][i]>df_col['playtime_forever'][i]>= df_col['Midian_playtime(min)'][i]*0.8:
            df_col['Assuming_Ratings'][i] = 4
        elif df_col['Midian_playtime(min)'][i]*0.8>df_col['playtime_forever'][i]>= df_col['Midian_playtime(min)'][i]*0.5:
            df_col['Assuming_Ratings'][i] = 3
        elif df_col['Midian_playtime(min)'][i]*0.5>df_col['playtime_forever'][i]>= df_col['Midian_playtime(min)'][i]*0.1:
            df_col['Assuming_Ratings'][i] = 2
        elif df_col['Midian_playtime(min)'][i]*0.1>df_col['playtime_forever'][i]:
            df_col['Assuming_Ratings'][i] = 1
    return df_col

def RDD_csv(df_col,i):
    df_col_text = df_col
    #df_col_text.drop(df_col_text.columns[[1,3]], axis = 1, inplace = True)
    #df_col_text.insert(0, "user_id",i)
    df_col_text['user_id'] = i 
    return df_col_text
#df_col_text_a4 = df_col_a4
#df_col_text_a4.drop(df_col_text_a4.columns[[1,3]], axis = 1, inplace = True)
#df_col_text_a4.insert(0, "user_id",4)

#############################        To assume a dataframe format        ##############################
df_col_text_ = []
df_col_a1 = get_ratings(get_df(requests.get(df_user_links['Links'][0])))
df_col_text_ = RDD_csv(df_col_a1,0)
df_col_text_.drop(df_col_text_.index[0:len(df_col_text_)],axis = 0)    ###########      Remove all the rows in a dataframe        ########
#len(df_col_text_ )     See the number of rows in dataframe  
#df_col_text_

df_col_text_ = df_col_text_.drop(df_col_text_.index[0:len(df_col_text_)],axis = 0) 

##############    To repeat, from here     ########################
for i in range(8):
    
    df_col_ = get_ratings(get_df(requests.get(df_user_links['Links'][i])))    ###### Anti_crawler when i >= 9
    
    df_col_text_element = RDD_csv(df_col_,i)
    df_col_text_ = df_col_text_.append(df_col_text_element)
    
#df_col_text__csv = df_col_text_[['appid','Assuming_Ratings','user_id']]
#df_col_text__csv.to_csv('df_col_use_app_raings_new.csv')

########################     Choose the columns that we need and store them as CSV      #######################

user_rating_df = pd.read_csv("df_col_use_app_raings_new.csv")
user_rating_df.head(5)
user_rating_df = user_rating_df.drop(['Unnamed: 0'], axis=1)


a0 = pd.DataFrame()
for i in range(8):
    #a0 = user_rating_df.loc[user_rating_df['user_id']==0]
    #a0 = a0.rename(columns={'Assuming_Ratings': 0})
    #a0 = a0.drop(['user_id'], axis=1)
#aa = a0.set_index('appid', inplace=True)
    a1 = user_rating_df.loc[user_rating_df['user_id']==i]
    a1 = a1.rename(columns={'Assuming_Ratings': 'ratings'})
    #a1 = a1.drop(['user_id'], axis=1)
#a1 = a1.set_index('appid', inplace=True)
    
    a0 = pd.concat([a0, a1], axis=0)

df = a0.pivot('appid', 'user_id','ratings')
df.head(5)
df.fillna(0.0, inplace = True)#################   Fill all the data with 0    ######################

from scipy.spatial.distance import cosine    ##################    1 - Cosine
from pandas import DataFrame
#https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cosine.html
cos_similarity = {}
for i in range(8):
    for j in range(8):
        a = 1 - cosine(df[i], df[j])
        
        cos_similarity.update({i:[a, j ]for j in range(8)})
cos_similarity
